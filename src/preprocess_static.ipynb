{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15d81dc-2317-40ff-b788-77336ef328a1",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "1. convenience functions for date processing\n",
    "2. fetch second latest static gtfs zips\n",
    "4. select relevant routes, trips and stop_times\n",
    "5. add start and end times for trips\n",
    "6. save filtered data to filesystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0842bff2-14d2-4679-b5cc-b170f33a0a45",
   "metadata": {},
   "source": [
    "Download latest rnv-gtfs data, unzip and read the data from the files:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c60b19-0068-4c9e-9e49-b576a4e99443",
   "metadata": {},
   "source": [
    "## 1. convenience functions for gtfs date formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f911fe9c-bc2f-444c-97ce-517d49e95ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def parseGtfsTimestringAsTimeObject(timestring:str):\n",
    "    # mod 24, because gtfs defines days as service days that can be longer than 24 hours, so 24:15 is a valid gtfs time\n",
    "    hour = int(timestring[0:2]) % 24\n",
    "    minute = int(timestring[3:5])\n",
    "    second = int(timestring[6:8])\n",
    "    #print(timestring)\n",
    "    #print(hour)\n",
    "    #print(minute) \n",
    "    #print(second)\n",
    "    return datetime.time(hour, minute, second)\n",
    "\n",
    "def parseGtfsDatestringAsDateObject(datestring:str):\n",
    "    year = int(datestring[0:4])\n",
    "    month = int(datestring[4:6])\n",
    "    day = int(datestring[6:8])\n",
    "    return datetime.date(year, month, day)\n",
    "\n",
    "def addSecondsToTimeObject(time:datetime.time, seconds) -> datetime.time:\n",
    "    datetime_object = datetime.datetime(100,1,1,time.hour, time.minute, time.second)\n",
    "    delta = datetime.timedelta(seconds=seconds)\n",
    "    return (datetime_object + delta).time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77562354-39f8-4d5f-8871-2e4e2218ec99",
   "metadata": {},
   "source": [
    "# 2. fetch second latest gtfs zip\n",
    "\n",
    "rnv publishes static gtfs on thursdays, with data valid from the following monday for 1-2 weeks. Therefore, we will always use the gtfs published in the previous week, to prevent switching to the latest one too early. \n",
    "\n",
    "convenience function for downloading and extracting zip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04045b79-0222-4815-9c8e-252d90fe20cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience function for downloading and extracting zip\n",
    "def download_and_extract_zip(url, extract_to='.'):\n",
    "    # download file\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  \n",
    "    \n",
    "    # extract in memory\n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
    "        # extract to disk\n",
    "        zip_ref.extractall(extract_to)\n",
    "        print(f\"extracted to '{extract_to}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0ca3fa-b780-4e4f-9e18-0ee401efbfd0",
   "metadata": {},
   "source": [
    "fetch and extract the gtfs zip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f48eb080-e83d-4612-8b97-10f852c52752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25\n",
      "2025-06-26\n",
      "2025-06-27\n",
      "2025-07-03\n",
      "https://gtfs-sandbox-dds.rnv-online.de/1750947188315/gtfs.zip\n",
      "extracted to './gtfs_full'\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv, DataFrame\n",
    "from os import path, getcwd, getenv\n",
    "from dotenv import load_dotenv\n",
    "import requests, zipfile, io\n",
    "import json\n",
    "    \n",
    "load_dotenv()\n",
    "# get array of definitions for the gtfs versions\n",
    "\n",
    "gtfs_base_url = getenv('gtfs_base_url')\n",
    "gtfs_version_overview_url = gtfs_base_url\n",
    "\n",
    "response = requests.get(gtfs_version_overview_url)\n",
    "\n",
    "gtfs_versions_dict = json.loads(response.text)\n",
    "\n",
    "# TODO pick correct gtfs by taking the one from last week\n",
    "\n",
    "gtfs_url = ''\n",
    "\n",
    "# search for gtfs of last week, once found, build gtfs_url\n",
    "today = datetime.date.today()\n",
    "days_since_last_sunday = today.weekday() + 1\n",
    "\n",
    "lastWeekEnd = today - datetime.timedelta(days = days_since_last_sunday)\n",
    "lastWeekStart = lastWeekEnd - datetime.timedelta(days = 6)\n",
    "\n",
    "# newest versions are at the end\n",
    "for i, gtfs_version in enumerate(gtfs_versions_dict[-4:]):\n",
    "    modifiedAt = datetime.datetime.fromtimestamp(gtfs_version['modified'] / 1000, datetime.UTC).date()  \n",
    "    print(modifiedAt)\n",
    "    # error in the api\n",
    "    # an old gtfs package was reuploaded  \n",
    "    if gtfs_version['modified'] == 1751033303000:\n",
    "        continue\n",
    "    if lastWeekStart <= modifiedAt <= lastWeekEnd:\n",
    "        gtfs_url = f\"{gtfs_base_url}/{gtfs_version['dir']}/gtfs.zip\"\n",
    "    \n",
    "\n",
    "if gtfs_url == '':\n",
    "    raise Exception()\n",
    "\n",
    "print(gtfs_url)\n",
    "\n",
    "# fetch data\n",
    "download_and_extract_zip(gtfs_url, './gtfs_full')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114b4cfd-38a8-4535-9be0-a54b73cfbe73",
   "metadata": {},
   "source": [
    "## 3. filter relevant routes, trips and stop_times\n",
    "\n",
    "Before we start, lets load the data from the filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cabe384-557e-407e-886c-86b6e122b210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read gtfs static data from files\n"
     ]
    }
   ],
   "source": [
    "gtfs_path = path.join(getcwd(), 'gtfs_full')\n",
    "calendar_path = path.join(gtfs_path, 'calendar.txt')\n",
    "routes_path = path.join(gtfs_path, 'routes.txt')\n",
    "trips_path = path.join(gtfs_path, 'trips.txt')\n",
    "stops_path = path.join(gtfs_path, 'stops.txt')\n",
    "stop_times_path = path.join(gtfs_path, 'stop_times.txt')\n",
    "\n",
    "calendar:DataFrame = read_csv(calendar_path)\n",
    "routes:DataFrame = read_csv(routes_path)\n",
    "trips:DataFrame = read_csv(trips_path)\n",
    "stops:DataFrame = read_csv(stops_path)\n",
    "stop_times:DataFrame = read_csv(stop_times_path)\n",
    "\n",
    "print('read gtfs static data from files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4675a638-a550-466c-96cb-13031617bba7",
   "metadata": {},
   "source": [
    "First, we want to remove all unneccessary data entries.\n",
    "As we will focus on the line 22 for the start, we only want routes, trips and stop_times for the line 22. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d898858-1341-4f03-9b5a-925d2d280b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_lines = ['22', '26', '5', '23', '21', '24']\n",
    "relevant_trip_prefixes = [line + \"-\" for line in relevant_lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221398a0-aec9-4cfc-b6c8-da800091205f",
   "metadata": {},
   "source": [
    "To achieve this, we firstly  select all rows from the routes that have a ´route_id´ starting with 22, indicating the route to be on line 22. By doing this instead of looking at the ´route_short_name´, special services like line E for shortened services to and from the depot are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9923234b-5684-479a-9d5b-b9b7b525a1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  151 routes on lines ['22', '26', '5', '23', '21', '24']\n",
      "     route_id route_short_name                     route_desc route_color\n",
      "146  26-41-26               26      Bismarckplatz - Kirchheim      F39B9B\n",
      "147   26-2-26               26      Bismarckplatz - Kirchheim      F39B9B\n",
      "148   26-1-26               26      Bismarckplatz - Kirchheim      F39B9B\n",
      "149   24-2-24               24  Handschuhsheim - Rohrbach Süd      8D2176\n",
      "150   24-1-24               24  Handschuhsheim - Rohrbach Süd      8D2176\n"
     ]
    }
   ],
   "source": [
    "# select relevant columns\n",
    "routes = routes[['route_id', 'route_short_name', 'route_desc', 'route_color']]\n",
    "\n",
    "# select only routes of relevant lines, indicated by the route_id \n",
    "routes = routes.loc[routes['route_id'].str.startswith(tuple(relevant_trip_prefixes))]\n",
    "\n",
    "print('found ',routes.shape[0], 'routes on lines', relevant_lines)\n",
    "print(routes.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d58e22c-1187-4133-ade0-a842d8d360f9",
   "metadata": {},
   "source": [
    "Let's do the same with trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f45a673-7057-412c-b75b-d2d324e7a7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  2456 trips on lines ['22', '26', '5', '23', '21', '24']\n",
      "     route_id          trip_id                                   service_id  \\\n",
      "886  26-41-26   26-41-51-17580  181-182-183-184-185-188-189-190-191-192-195   \n",
      "887   26-2-26  26-2-1026-42420  181-182-183-184-185-188-189-190-191-192-195   \n",
      "888   26-1-26  26-1-1026-40020  181-182-183-184-185-188-189-190-191-192-195   \n",
      "889   24-2-24  24-2-1024-38460  181-182-183-184-185-188-189-190-191-192-195   \n",
      "890   24-1-24     24-1-1-36420  181-182-183-184-185-188-189-190-191-192-195   \n",
      "\n",
      "    trip_short_name  \n",
      "886              26  \n",
      "887              26  \n",
      "888              26  \n",
      "889              24  \n",
      "890              24  \n"
     ]
    }
   ],
   "source": [
    "# select relevant columns\n",
    "trips = trips[[\"route_id\",\"trip_id\", \"service_id\", \"trip_short_name\"]]\n",
    "\n",
    "# select only trips of relevant lines, indicated by the trip_id \n",
    "trips = trips.loc[trips['trip_id'].str.startswith(tuple(relevant_trip_prefixes))]\n",
    "\n",
    "print('found ',trips.shape[0], 'trips on lines', relevant_lines)\n",
    "print(trips.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b5ea8-a313-425d-8888-f1b5e4f1bbcb",
   "metadata": {},
   "source": [
    "And finally, we also filter the stop_times by looking at the prefix of the trip_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c4ddab7-ce03-4719-8484-0153c0e89948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  57795 stop times on lines ['22', '26', '5', '23', '21', '24']\n",
      "              trip_id arrival_time departure_time  stop_sequence  stop_id\n",
      "14669  26-41-51-17580     04:53:00       04:53:00              1   115122\n",
      "14670  26-41-51-17580     04:55:00       04:55:00              2   427404\n",
      "14671  26-41-51-17580     04:56:00       04:56:00              3   427202\n",
      "14672  26-41-51-17580     04:58:00       04:58:00              4   114922\n",
      "14673  26-41-51-17580     05:00:00       05:00:00              5   679502\n"
     ]
    }
   ],
   "source": [
    "# select relevant columns\n",
    "stop_times = stop_times[[\"trip_id\", \"arrival_time\", \"departure_time\", \"stop_sequence\", \"stop_id\"]]\n",
    "\n",
    "# select only stop_times of relevant lines, indicated by the trip_id \n",
    "stop_times = stop_times.loc[stop_times['trip_id'].str.startswith(tuple(relevant_trip_prefixes))]\n",
    "\n",
    "print('found ',stop_times.shape[0], 'stop times on lines', relevant_lines)\n",
    "print(stop_times.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760b64aa-0e15-4dce-9fe6-6ebcc41adda0",
   "metadata": {},
   "source": [
    "## 4. (optional) adjust arrivals and departures for visualization\n",
    "The schedule only uses minutes and not seconds. This results in most stops having a standing time of 0 seconds. At the same time, there are no two stops that are scheduled to arrive in the same minute. Therefore, we can manually add an artificial departure delay of 15 seconds, which we will account for when dealing with real time delays later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "602cf9b4-c2b9-424a-b9f7-8744ef57bce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              trip_id arrival_time departure_time  stop_sequence  stop_id\n",
      "14669  26-41-51-17580     04:53:00       04:53:15              1   115122\n",
      "14670  26-41-51-17580     04:55:00       04:55:15              2   427404\n",
      "14671  26-41-51-17580     04:56:00       04:56:15              3   427202\n",
      "14672  26-41-51-17580     04:58:00       04:58:15              4   114922\n",
      "14673  26-41-51-17580     05:00:00       05:00:15              5   679502\n"
     ]
    }
   ],
   "source": [
    "def addArtificialDepartureDelay(row):\n",
    "    departure_time_object = parseGtfsTimestringAsTimeObject(row['departure_time'])\n",
    "    adjusted_departure_time_object = addSecondsToTimeObject(departure_time_object, 15)\n",
    "    row['departure_time'] = adjusted_departure_time_object.isoformat()\n",
    "    return row\n",
    "\n",
    "stop_times = stop_times.apply(addArtificialDepartureDelay, axis=1)\n",
    "print(stop_times[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7819bcf7-60d6-4827-887e-2b79cea38c4d",
   "metadata": {},
   "source": [
    "## 5. add start and end times to trips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1546e223-3732-410b-9fdd-4b6305296880",
   "metadata": {},
   "source": [
    "To make it easy to identify the active trips, we will now add start and end times to each trip.\n",
    "First, we will create a function to get all the stop_times for a specific ´trip_id´. Then we will sort the stop_times and return the first ´arrival_time´ as trip start and the last ´departure_time´ as trip end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "133b9eba-cddb-4481-bad7-cd2dadaed098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trip_id: 26-41-51-17580 \n",
      "Trip Start Time:  04:53:00 \n",
      "Trip End Time:  05:07:15\n"
     ]
    }
   ],
   "source": [
    "def getTripStartTime(trip_id:str) -> tuple[str, str]:\n",
    "    relevant_stop_times = stop_times.loc[stop_times['trip_id'] == trip_id]\n",
    "    #print('found ',relevant_stop_times.shape[0], 'relevant stop times for trip_id', trip_id)\n",
    "    \n",
    "    relevant_stop_times = relevant_stop_times.sort_values(by=['stop_sequence'])\n",
    "    \n",
    "    first_stop = relevant_stop_times.iloc[0]\n",
    "    trip_start_time = first_stop.loc['arrival_time']\n",
    "    \n",
    "    return trip_start_time\n",
    "\n",
    "def getTripEndTime(trip_id:str) -> tuple[str, str]:\n",
    "    relevant_stop_times = stop_times.loc[stop_times['trip_id'] == trip_id]\n",
    "    #print('found ',relevant_stop_times.shape[0], 'relevant stop times for trip_id', trip_id)\n",
    "    \n",
    "    relevant_stop_times = relevant_stop_times.sort_values(by=['stop_sequence'])\n",
    "    \n",
    "    last_stop = relevant_stop_times.iloc[-1]\n",
    "    trip_end_time = last_stop.loc['departure_time']\n",
    "    \n",
    "    return trip_end_time\n",
    "\n",
    "example_trip_id = trips.iloc[0].loc['trip_id']\n",
    "example_start = getTripStartTime(example_trip_id)\n",
    "example_end = getTripEndTime(example_trip_id)\n",
    "print('trip_id:', example_trip_id, '\\nTrip Start Time: ', example_start, '\\nTrip End Time: ', example_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6c5b9-8cb2-4f4a-9760-a93086d92448",
   "metadata": {},
   "source": [
    "Now let's add the new columns by using the function we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92dde7db-ce54-4be1-a5f4-0a6321cf7026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     route_id          trip_id                                   service_id  \\\n",
      "886  26-41-26   26-41-51-17580  181-182-183-184-185-188-189-190-191-192-195   \n",
      "887   26-2-26  26-2-1026-42420  181-182-183-184-185-188-189-190-191-192-195   \n",
      "888   26-1-26  26-1-1026-40020  181-182-183-184-185-188-189-190-191-192-195   \n",
      "889   24-2-24  24-2-1024-38460  181-182-183-184-185-188-189-190-191-192-195   \n",
      "890   24-1-24     24-1-1-36420  181-182-183-184-185-188-189-190-191-192-195   \n",
      "\n",
      "    trip_short_name start_time  end_time  \n",
      "886              26   04:53:00  05:07:15  \n",
      "887              26   11:47:00  12:16:15  \n",
      "888              26   11:07:00  11:37:15  \n",
      "889              24   10:41:00  11:06:15  \n",
      "890              24   10:07:00  10:33:15  \n"
     ]
    }
   ],
   "source": [
    "trips['start_time'] = trips.apply(lambda row: getTripStartTime(row['trip_id']), axis=1)\n",
    "trips['end_time'] = trips.apply(lambda row: getTripEndTime(row['trip_id']), axis=1)\n",
    "\n",
    "print(trips.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e919a-e5c6-4e71-a700-d7718024e451",
   "metadata": {},
   "source": [
    "## 6. save filtered data to filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0548de7d-3e23-4835-96d3-b95227d4473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "gtfs_filtered_path = path.join(getcwd(), 'gtfs_filtered')\n",
    "\n",
    "if not os.path.exists(gtfs_filtered_path):\n",
    "   os.makedirs(gtfs_filtered_path)\n",
    "\n",
    "calendar_filtered_path = path.join(gtfs_filtered_path, 'calendar.txt')\n",
    "routes_filtered_path = path.join(gtfs_filtered_path, 'routes.txt')\n",
    "trips_filtered_path = path.join(gtfs_filtered_path, 'trips.txt')\n",
    "stops_filtered_path = path.join(gtfs_filtered_path, 'stops.txt')\n",
    "stop_times_filtered_path = path.join(gtfs_filtered_path, 'stop_times.txt')\n",
    "\n",
    "\n",
    "calendar.to_csv(calendar_filtered_path, index=False)\n",
    "routes.to_csv(routes_filtered_path, index=False)\n",
    "trips.to_csv(trips_filtered_path, index=False)\n",
    "stops.to_csv(stops_filtered_path, index=False)\n",
    "stop_times.to_csv(stop_times_filtered_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f9cb43-1d00-4e10-b9c5-7a7c29dffdfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
